{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nwXIlMHokOW"
   },
   "source": [
    "# **C like Code generation with LSTM**\n",
    "\n",
    "In this project we are aiming to produce code which looks like any generic C like program. We know that text is sequential data, i.e. the next character depends on the previous character. As a result we choose one of the many Recurrent cells available in the **tensorflow.keras** module - The LSTM cell.\n",
    "\n",
    "We are going for basic character level text generation. As this level of text generation works better for body of text with less number of different words. C like programs do not have many words when it comes in comparison to texts like novels or poems or other literary data.\n",
    "\n",
    "\n",
    "Let us start by first importing the libraries and taking a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NCEo-IosFOn"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93Y22qYdqKAm"
   },
   "source": [
    "Now we are going to open our text file, it is UTF-8 encoded. From this file we are going to get our text corpus (body of text). We then find every new character and add it to a list. This list is going to be out character dictionary. \n",
    "\n",
    "The model will get the index of the characters in the character dictionary as an input and it will predict the index of the character which is going to be followed. We thus convert the characters to integers for the model for an easy representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "jjpl6_mCsm-U",
    "outputId": "ddf31611-a880-4f1c-fad4-e74c68cc928d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 319705\n",
      "total chars: 70\n"
     ]
    }
   ],
   "source": [
    "with io.open(\"/content/final.txt\", encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJP_2fq5wryf"
   },
   "source": [
    "**Now we need to vectorize the input and the output.**\n",
    "\n",
    "We start by splitting the text into random segments of a selected maximum length. After we have retrived the sentence we will store the character next to the sentence as the target chracter.\n",
    "\n",
    "Keeping this is mind:\n",
    "1.   The indexes of the characters from the sentences turn into our input vector.\n",
    "2.   The (index of the) character next to our sentence becomes our target y.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "XHaeeoSwsrPr",
    "outputId": "7b2e6350-5412-42d6-b3df-efbcb17dc385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 79914\n",
      "Vectorization\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 50\n",
    "step = 4\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LV9sNbR7WfbZ"
   },
   "source": [
    "***LSTMs - A brief.***\n",
    "\n",
    "Recurrent Neural Networks work just fine when we are dealing with short-term dependencies. However, vanilla RNNs fail to understand the context behind an input. The reason behind this is the problem of **Vanishing Gradient**.\n",
    "\n",
    "*What is the vanishing graident problem ?*\n",
    "\n",
    "> As more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train. For shallow network with only a few layers that use these activations, this isn’t a big problem. However, when more layers are used, it can cause the gradient to be too small for training to work effectively.\n",
    "\n",
    "As a solution to this problem of Vanilla RNNs, LSTM was proposed in 1997 by [Sepp Hochreiter and Jürgen Schmidhuber](http://www.bioinf.jku.at/publications/older/2604.pdf). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n",
    "\n",
    "Intuitively, the cell is responsible for keeping track of the dependencies between the elements in the input sequence. The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit. \n",
    "\n",
    "\n",
    "![Basic Structure of LSTM cell - Image from Wikipedia](https://upload.wikimedia.org/wikipedia/commons/3/3b/The_LSTM_cell.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrNItjtbyI7z"
   },
   "source": [
    "Now comes the most important part of our endeavour. Creating the Neural Network Model which can learn (or atleast fake) writing a C like program segment.\n",
    "\n",
    "Things to keep in mind:\n",
    "1.   The model consists of two main layers - The LSTM Layer and The Dense connected layer.\n",
    "2.   The LSTM layer gets the vectorized character inputs from the character dictionary and has 128 units.\n",
    "3.   The LSTM layer has an 'ReLU' activation which stands for rectified linear unit and is used to break symmetry in the initial layer of the model.\n",
    "4.   The Dense layer has a softmax output. The softmax activation produces probabilities for the index as output.\n",
    "\n",
    "The Model has been complied with RMSprop optimizer which a standard speedup for gradient descent, and categorical_crossentropy loss which is used when we need to predict probabilites for various categories (in this case the categories are the characters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "OGmMETUbsvJZ",
    "outputId": "3a31c2e7-5f26-4944-8775-0b5a6ea991e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 64)                34560     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 70)                4550      \n",
      "=================================================================\n",
      "Total params: 39,110\n",
      "Trainable params: 39,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Building model')\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBJgw7y2_jk3"
   },
   "source": [
    "**Let us see how the model looks like.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "IMep0yV31VkF",
    "outputId": "9a2dc6f1-3bd1-40c8-93ef-22c686bc02eb"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"184pt\" viewBox=\"0.00 0.00 332.00 221.00\" width=\"277pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 328,-217 328,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140404104023400 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140404104023400</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 324,-212.5 324,-166.5 0,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-185.8\">lstm_9_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"164,-166.5 164,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"164,-189.5 222,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-166.5 222,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-197.3\">(None, 50, 70)</text>\n",
       "<polyline fill=\"none\" points=\"222,-189.5 324,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-174.3\">(None, 50, 70)</text>\n",
       "</g>\n",
       "<!-- 140404104022896 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140404104022896</title>\n",
       "<polygon fill=\"none\" points=\"31,-83.5 31,-129.5 293,-129.5 293,-83.5 31,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-102.8\">lstm_9: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"133,-83.5 133,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"133,-106.5 191,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191,-83.5 191,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-114.3\">(None, 50, 70)</text>\n",
       "<polyline fill=\"none\" points=\"191,-106.5 293,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-91.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 140404104023400&#45;&gt;140404104022896 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140404104023400-&gt;140404104022896</title>\n",
       "<path d=\"M162,-166.3799C162,-158.1745 162,-148.7679 162,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.5001,-139.784 162,-129.784 158.5001,-139.784 165.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140404104023008 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140404104023008</title>\n",
       "<polygon fill=\"none\" points=\"39.5,-.5 39.5,-46.5 284.5,-46.5 284.5,-.5 39.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"93\" y=\"-19.8\">dense_9: Dense</text>\n",
       "<polyline fill=\"none\" points=\"146.5,-.5 146.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"146.5,-23.5 204.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-.5 204.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-31.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-23.5 284.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-8.3\">(None, 70)</text>\n",
       "</g>\n",
       "<!-- 140404104022896&#45;&gt;140404104023008 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140404104022896-&gt;140404104023008</title>\n",
       "<path d=\"M162,-83.3799C162,-75.1745 162,-65.7679 162,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.5001,-56.784 162,-46.784 158.5001,-56.784 165.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, dpi=60).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6391zq1J9TF"
   },
   "source": [
    "**Now we train our model.**\n",
    "\n",
    "We use the fit() function which takes care of our training. The parameters x and y are the input and corresponding output vectors.\n",
    "\n",
    "Hyperparamters:\n",
    "\n",
    "1.   Batch size = 128\n",
    "2.   Epochs = 50\n",
    "\n",
    "The training history has been saved in a History.history object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "HhW4wQRas7AT",
    "outputId": "e1e182d3-10df-4270-ccc5-91a98ef0cab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, batch_size=128, epochs=50, verbose = 0)\n",
    "print(\"Training Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2YFyIEyLIPg"
   },
   "source": [
    "Now plotting the **loss graph** for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "5_eldcrhLbHB",
    "outputId": "fc93a5aa-2581-4029-fefb-1783b761f1e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQ2uKIdrLrc7"
   },
   "source": [
    "Now we generate output using standard **temperature sampling** which is suggested for NLP projects. The temperature paramater decides the diversity of the sampling. The high temperature sample displays greater linguistic variety, but the low temperature sample is more grammatically correct. Lowering the temperature allows you to focus on higher probability output sequences and smooth over deficiencies of the model. The helper function to sample an index from a probability array.\n",
    "\n",
    "The custom_pred function can be given a C-Like code which it can use as the seed for generating sentences which are supposed to look like C code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q02vaaCi-7l3"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def custom_pred(s = \"\"):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('Diversity:', diversity,\"\\n\")\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        if len(s) != 0:\n",
    "            sentence = s\n",
    "        else:\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('Generating with seed: \"' + sentence + '\"'+\"\\n\")\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kt1EMTdvPSr4"
   },
   "source": [
    "The following line is a call to the custom_pred function which generates C like code.\n",
    "\n",
    "Moment of truth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6NH5J9LLCepI",
    "outputId": "72851ddc-cd53-4cdc-9d4e-961cf440c6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity: 0.2 \n",
      "\n",
      "Generating with seed: \"y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_s\"\n",
      "\n",
      "y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_syswmevent(event);\n",
      "    sdl_syswmevent(event, size_t chunk_olus, sdl_strclllock_tromevents * sdl_strlen;\n",
      "    sdl_event_watchers_lock);\n",
      "    sdl_strlen(m, sdl_touch->couse_watchers[i].dollarte(sdl_strled.hersize);\n",
      "                                                                                                                                                                                              \n",
      "Diversity: 0.5 \n",
      "\n",
      "Generating with seed: \"y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_s\"\n",
      "\n",
      "y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_syswmeventche(sdl_windowevent_cos(userdagn);\n",
      "                            assert(int * = (size_t);\n",
      "                                                                                                                                                                                                                                                                                                               \n",
      "Diversity: 1.0 \n",
      "\n",
      "Generating with seed: \"y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_s\"\n",
      "\n",
      "y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_sesture(mouse->dollartetp) {\n",
      "        if (4 != 0) {\n",
      "            uint8 *p = (uint8 *) small_size_size\n",
      "#define dwoul|mivefize\n",
      "#define \\\n",
      "             ((m1sthint)- rshut\",\n",
      "          (size_s));\n",
      "#endif\n",
      "#dec pring = small_charnucting_as (m, amaall, smmallbarl.window_moved, nb +; chunk2map) = void *start, smalloce#, *empaicisition\\ndefatigicpive_tyremap(int, sdl_setata(sdl_touch));\n",
      "    sdl_x * 0 0;\n",
      "\n",
      "    ret\n",
      "Diversity: 1.2 \n",
      "\n",
      "Generating with seed: \"y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_s\"\n",
      "\n",
      "y *free;\n",
      "    sdl_syswmentry *wmmsg_used;\n",
      "    sdl_sys\t{ gi->chunk_size_t_enmal_str2f3,\n",
      "    qs3+338146666  #elsendlingevadhry (w2int) {          por cas_mpy t= smalloc_event(elemente_ad_chunk(!mchint);\n",
      "        orefin\"iath[2] = (tchunkpa,len);\n",
      "        while (sdl_sys_mmmp\tudesre(d, smutcp)), rstart;\n",
      "#endif\n",
      "#_mempa[e)\n",
      "    0, 'f')\n",
      "     \n",
      "    nmouseptcal(x, x);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#ifldef swil\n",
      "leans (pta, &8mami, mr,com_sy, int c, os2*);\n",
      "}\n",
      "\n",
      "\n",
      "#include \"sdlatflsf(dionb))\n"
     ]
    }
   ],
   "source": [
    "custom_pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qO0xfXCBPjSu"
   },
   "source": [
    "Well, that does look like C code. However under no circumstances can this code be complied. It is beautiful work around for writing C code. However this projects has huge grounds for improvement.\n",
    "\n",
    "Although we can note that with increasing diversity the code gets more unreadable or starts making lesser sense. However we have completed our objective of producing C like code using Keras and a dataset of C programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mG2OWsH_LvCh"
   },
   "source": [
    "Made by:\n",
    "\n",
    "*   Shayak Chakraborty\n",
    "*   Jayanta Banik\n",
    "*   Shubham Addhya\n",
    "\n",
    "**END OF NOTEBOOK**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CCodeGen.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
